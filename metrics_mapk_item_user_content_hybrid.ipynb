{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix\n",
    "# from src.mapk import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pymongo import MongoClient\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb://root:password@localhost:27017/\")\n",
    "\n",
    "db = client[\"anime\"]\n",
    "collection = db[\"animelist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Файлы\n",
    "INPUT_DIR = 'C:/Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение файлов с рейтингами пользователей для каждого аниме\n",
    "anime_ratings = pd.read_csv(INPUT_DIR + '/rating_complete.csv',\n",
    "                        low_memory=False,\n",
    "                        decimal=',',\n",
    "                        usecols=[\"user_id\",\"anime_id\",\"rating\"]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (60% train, 40% test)\n",
    "anime_ratings, train_ratings = train_test_split(anime_ratings, test_size=0.6, random_state=42)\n",
    "\n",
    "# (50% train, 50% test)\n",
    "train_ratings, test_ratings = train_test_split(train_ratings, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пользователь должен оценить минимум 500 аниме (train_ratings)\n",
    "ntrain_ratings = train_ratings['user_id'].value_counts()\n",
    "train_ratings = train_ratings[train_ratings['user_id'].isin(ntrain_ratings[ntrain_ratings >= 500].index)].copy()\n",
    "# Пользователь должен оценить минимум 500 аниме (test_ratings)\n",
    "ntest_ratings = test_ratings['user_id'].value_counts()\n",
    "test_ratings = test_ratings[test_ratings['user_id'].isin(ntest_ratings[ntest_ratings >= 500].index)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаление Duplicated Rows\n",
    "train_ratings = train_ratings.drop_duplicates()\n",
    "test_ratings = test_ratings.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание сводной таблицы (pivot table). \n",
    "# По горизонтали будут аниме, по вертикали - пользователи, значения - оценки\n",
    "user_item_matrix_train = train_ratings.pivot(index = 'anime_id', columns = 'user_id', values= 'rating')\n",
    "\n",
    "# NaN преобразовываю в нули\n",
    "user_item_matrix_train.fillna(0, inplace = True)\n",
    "\n",
    "# Преобразую разреженную матрицу в формат csr\n",
    "# Метод values передаст функции csr_matrix только значения датафрейма\n",
    "csr_data_train = csr_matrix(user_item_matrix_train.values)\n",
    "\n",
    "# Сброшу индекс с помощью reset_index()\n",
    "user_item_matrix_train = user_item_matrix_train.rename_axis(None, axis = 1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт модуля functools для использования декоратора lru_cache\n",
    "from functools import lru_cache\n",
    "\n",
    "# Получение данных об аниме с кэшированием результатов\n",
    "@lru_cache(maxsize=None)\n",
    "def load_anime_data():\n",
    "    anime_data = []\n",
    "    for document in collection.find():\n",
    "        anime_id = document.get('anime_id')\n",
    "        title = document.get('title')\n",
    "        synopsis = document.get('synopsis')\n",
    "        anime_data.append({\n",
    "            'anime_id': anime_id,\n",
    "            'title': title,\n",
    "            'synopsis': synopsis\n",
    "        })\n",
    "    return anime_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item-based\n",
    "def get_item_based_recommendations(search_words, n_recommendations=10):\n",
    "    anime_data = load_anime_data()  # Загрузка данных\n",
    "\n",
    "    recommendations = []\n",
    "    knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)\n",
    "    knn.fit(csr_data_train)\n",
    "\n",
    "    anime_ids = []  # Создание пустого списка для хранения идентификаторов аниме\n",
    "\n",
    "    for word in search_words:\n",
    "        # Фильтрация аниме по заданному слову в заголовке\n",
    "        anime_search = [anime for anime in anime_data if word in anime['title']]\n",
    "        if not anime_search:\n",
    "            continue\n",
    "        anime_id = anime_search[0]['anime_id']\n",
    "\n",
    "        # Преобразование anime_id в индекс матрицы\n",
    "        anime_id = user_item_matrix_train[user_item_matrix_train['anime_id'] == anime_id].index[0]\n",
    "\n",
    "        # Поиск ближайших соседей и расстояний до них\n",
    "        distances, indices = knn.kneighbors(csr_data_train[anime_id], n_neighbors=n_recommendations + 1)\n",
    "        indices_list = indices.squeeze().tolist()[1:]\n",
    "        distances_list = distances.squeeze().tolist()[1:]\n",
    "        indices_distances = list(zip(indices_list, distances_list))\n",
    "\n",
    "        # Получение рекомендаций и добавление идентификаторов аниме в список\n",
    "        for ind_dist in indices_distances:\n",
    "            anime_id = int(user_item_matrix_train.iloc[ind_dist[0]]['anime_id'])\n",
    "            anime_ids.append(anime_id)\n",
    "\n",
    "    return anime_ids[:n_recommendations]  # Возвращаем только список идентификаторов аниме\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4437, 5114, 10863, 14227, 2251, 9062, 1519, 9515, 30, 14813]\n"
     ]
    }
   ],
   "source": [
    "print(get_item_based_recommendations(['Naruto', 'Bleach'], 10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(algorithm='brute', metric='cosine')"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создание матрицы пользователь-аниме\n",
    "user_anime_matrix = csr_matrix((train_ratings['rating'],\n",
    "                                (train_ratings['user_id'], train_ratings['anime_id'])))\n",
    "\n",
    "# Создание модели NearestNeighbors\n",
    "model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "model.fit(user_anime_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-based\n",
    "def get_user_based_recommendations(user_id, n_recommendations=10):\n",
    "    # Загрузка данных об аниме\n",
    "    anime_data = load_anime_data()\n",
    "    \n",
    "    # Получение оценок выбранного пользователя\n",
    "    user_rated_anime = train_ratings[train_ratings['user_id'] == user_id]['anime_id'].unique()\n",
    "\n",
    "    # Нахождение индексов наиболее похожих пользователей\n",
    "    similar_users = model.kneighbors(user_anime_matrix[user_id], n_neighbors=n_recommendations)[1].flatten()\n",
    "\n",
    "    # Получение списка аниме, оцененных найденными похожими пользователями\n",
    "    similar_anime = train_ratings[train_ratings['user_id'].isin(similar_users)]['anime_id'].unique()\n",
    "\n",
    "    # Исключение аниме, которые уже оценил выбранный пользователь\n",
    "    recommended_anime = [anime_id for anime_id in similar_anime if anime_id not in user_rated_anime]\n",
    "\n",
    "    # Получение данных о рекомендуемом аниме\n",
    "    recommended_anime_data = [anime['anime_id'] for anime in anime_data if anime['anime_id'] in recommended_anime]\n",
    "\n",
    "    # Список рекомендуемого аниме\n",
    "    return recommended_anime_data[:n_recommendations]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50579508</th>\n",
       "      <td>310065</td>\n",
       "      <td>32900</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733703</th>\n",
       "      <td>10851</td>\n",
       "      <td>19023</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16250982</th>\n",
       "      <td>99690</td>\n",
       "      <td>819</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35925526</th>\n",
       "      <td>220437</td>\n",
       "      <td>35069</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  anime_id  rating\n",
       "50579508   310065     32900       7\n",
       "1733703     10851     19023       5\n",
       "16250982    99690       819       4\n",
       "35925526   220437     35069       2"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratings.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 7, 8, 17, 19, 20, 24, 25, 27, 28]\n"
     ]
    }
   ],
   "source": [
    "print(get_user_based_recommendations(220437, 10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conten-based\n",
    "def get_content_based_recommendations(search_words, n_recommendations=10):\n",
    "    anime_data = load_anime_data()  # Загружаем данные \n",
    "\n",
    "    # Создание матрицы признаков на основе synopsis (content-based)\n",
    "    content_matrix = pd.DataFrame(anime_data)  # Создаем DataFrame из данных аниме\n",
    "    content_matrix['synopsis'] = content_matrix['synopsis'].fillna('')  # Заполняем пропущенные значения в столбце \"synopsis\" пустой строкой\n",
    "\n",
    "    tfidf = TfidfVectorizer(stop_words='english')  # Создаем объект TfidfVectorizer для создания матрицы TF-IDF\n",
    "    tfidf_matrix = tfidf.fit_transform(content_matrix['synopsis'].values.astype('U'))  # Преобразуем synopsis в TF-IDF матрицу признаков\n",
    "\n",
    "    knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=n_recommendations+1, n_jobs=-1)  # Инициализируем модель NearestNeighbors для поиска ближайших соседей\n",
    "    knn.fit(tfidf_matrix)  # Обучаем модель на матрице признаков\n",
    "\n",
    "    recommendations = []\n",
    "\n",
    "    for word in search_words:\n",
    "        anime_search = content_matrix[content_matrix['title'].str.contains(word, case=False)]  # Ищем аниме, в названии которого есть заданное слово (без учета регистра)\n",
    "\n",
    "        if anime_search.empty:\n",
    "            continue\n",
    "\n",
    "        anime_ids = anime_search['anime_id'].values\n",
    "        anime_recommendations = []\n",
    "\n",
    "        for anime_id in anime_ids:\n",
    "            anime_index = content_matrix[content_matrix['anime_id'] == anime_id].index[0]\n",
    "            distances, indices = knn.kneighbors(tfidf_matrix[anime_index], n_neighbors=n_recommendations + 1)\n",
    "            indices_list = indices.squeeze()[1:].tolist()  # Исключаем первый элемент, который является самим аниме\n",
    "            anime_recommendations.extend(indices_list)\n",
    "\n",
    "        anime_recommendations = list(set(anime_recommendations))[:n_recommendations]  # Извлекаем n уникальных рекомендаций\n",
    "\n",
    "        for anime_index in anime_recommendations:\n",
    "            anime_id = content_matrix.loc[anime_index]['anime_id']\n",
    "            if anime_id not in anime_ids:\n",
    "                recommendations.append(anime_id)\n",
    "\n",
    "    return recommendations[:n_recommendations]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6573, 34683, 28953, 20757, 2822, 25861, 20871, 42317, 553, 34688]\n"
     ]
    }
   ],
   "source": [
    "print(get_content_based_recommendations(['Naruto', 'Bleach'], 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid\n",
    "def merge_recommendations(search_words, n_recommendations, user_id, recommendations_count):\n",
    "    # Получение рекомендаций с использованием content-based метода\n",
    "    content_based = get_content_based_recommendations(search_words, recommendations_count)\n",
    "    \n",
    "    # Получение рекомендаций с использованием user-based метода\n",
    "    user_based = get_user_based_recommendations(user_id, recommendations_count)\n",
    "    \n",
    "    # Получение рекомендаций с использованием item-based метода\n",
    "    item_based = get_item_based_recommendations(search_words, recommendations_count)\n",
    "    \n",
    "    # Объединение всех рекомендаций в один список\n",
    "    all_recommendations = content_based + user_based + item_based\n",
    "    \n",
    "    # Удаление дубликатов\n",
    "    unique_recommendations = list(set(all_recommendations))\n",
    "    \n",
    "    return unique_recommendations[:recommendations_count]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34688, 1, 25861, 2822, 20871, 6, 7, 15, 16, 17]\n"
     ]
    }
   ],
   "source": [
    "print(merge_recommendations(['Naruto', 'Bleach'], 10, 310065, 10 ))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_recommendations = []\n",
    "for user_id in test_ratings['user_id'].unique():\n",
    "    user_actual_items = test_ratings[test_ratings['user_id'] == user_id]['anime_id'].unique()\n",
    "    actual_recommendations.append(list(user_actual_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Вычисляет метрику MAPK@k для оценки эффективности рекомендательной системы.\n",
    "\n",
    "    Параметры:\n",
    "    actual (list): Список фактических рекомендаций для каждого пользователя.\n",
    "    predicted (list): Список предсказанных рекомендаций для каждого пользователя.\n",
    "    k (int): Количество рекомендаций для оценки.\n",
    "\n",
    "    Возвращает:\n",
    "    float: Значение метрики MAPK@k.\n",
    "    \"\"\"\n",
    "    mapk_sum = 0\n",
    "    for i in range(len(actual)):\n",
    "        actual_i = actual[i]\n",
    "        predicted_i = predicted[i][:k]\n",
    "\n",
    "        # Подсчет числа правильных предсказаний в топ-k\n",
    "        num_correct = 0\n",
    "        for j in range(len(predicted_i)):\n",
    "            if predicted_i[j] in actual_i:\n",
    "                num_correct += 1\n",
    "\n",
    "        # Вычисление точности в топ-k\n",
    "        precision = num_correct / k\n",
    "\n",
    "        # Добавление точности в сумму MAPK\n",
    "        mapk_sum += precision\n",
    "\n",
    "    # Вычисление средней точности MAPK\n",
    "    mapk_score = mapk_sum / len(actual)\n",
    "\n",
    "    return mapk_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPK@10 for item-based: 0.23633663366336574\n",
      "MAPK@10 for user-based: 0.18643564356435585\n",
      "MAPK@10 for content-based: 0.05009900990099045\n",
      "MAPK@10 for hybrid-based: 0.13306930693069255\n"
     ]
    }
   ],
   "source": [
    "# Получение фактических рекомендаций\n",
    "actual_recommendations = []\n",
    "for user_id in test_ratings['user_id'].unique():\n",
    "    user_actual_items = test_ratings[test_ratings['user_id'] == user_id]['anime_id'].unique()\n",
    "    actual_recommendations.append(list(user_actual_items))\n",
    "\n",
    "# Получение предсказанных рекомендаций для каждого типа рекомендательной системы\n",
    "item_based_recommendations = []\n",
    "user_based_recommendations = []\n",
    "content_based_recommendations = []\n",
    "hybrid_recommendations = []\n",
    "\n",
    "for user_id in test_ratings['user_id'].unique():\n",
    "    search_words = ['Naruto', 'Bleach']  # Задайте соответствующие поисковые слова для content-based и hybrid-based рекомендаций\n",
    "    n_recommendations = 10  # Количество рекомендаций для каждого типа рекомендательной системы\n",
    "\n",
    "    item_based_rec = get_item_based_recommendations(search_words, n_recommendations)\n",
    "    user_based_rec = get_user_based_recommendations(user_id, n_recommendations)\n",
    "    content_based_rec = get_content_based_recommendations(search_words, n_recommendations)\n",
    "    hybrid_rec = merge_recommendations(search_words, n_recommendations, user_id, n_recommendations)\n",
    "\n",
    "    item_based_recommendations.append(item_based_rec)\n",
    "    user_based_recommendations.append(user_based_rec)\n",
    "    content_based_recommendations.append(content_based_rec)\n",
    "    hybrid_recommendations.append(hybrid_rec)\n",
    "\n",
    "# Вычисление метрики MAPK@10 для каждого типа рекомендательной системы\n",
    "mapk_item_based = mapk(actual_recommendations, item_based_recommendations)\n",
    "mapk_user_based = mapk(actual_recommendations, user_based_recommendations)\n",
    "mapk_content_based = mapk(actual_recommendations, content_based_recommendations)\n",
    "mapk_hybrid_based = mapk(actual_recommendations, hybrid_recommendations)\n",
    "\n",
    "print(\"MAPK@10 for item-based:\", mapk_item_based)\n",
    "print(\"MAPK@10 for user-based:\", mapk_user_based)\n",
    "print(\"MAPK@10 for content-based:\", mapk_content_based)\n",
    "print(\"MAPK@10 for hybrid-based:\", mapk_hybrid_based)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
